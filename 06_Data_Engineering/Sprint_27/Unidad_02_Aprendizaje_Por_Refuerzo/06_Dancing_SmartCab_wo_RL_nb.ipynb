{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![logo](./img/TheBridge_RL.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Taxi Aut\u00f3nomo (Smartcab), sin RL"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Contenidos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["* [Definicion del Problema](#Definicion-del-Problema)  ", "\n", "* [Creando el entorno](#Creando-el-entorno)  ", "\n", "* [Sin aprendizaje por refuerzo](#Sin-aprendizaje-por-refuerzo)  ", "\n", "* [Visualizacion](#Visualizacion)  ", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Definicion del Problema  ", "\n", "[al indice](#Contenidos)  ", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["__Hay 4 ubicaciones (etiquetadas con diferentes letras) y nuestro trabajo es recoger al pasajero en una ubicaci\u00f3n y dejarlo en otra.__"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"./img/Reinforcement_Learning_Taxi_Env.png\" alt=\"drawing\" width=\"600\"/>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Recuerda, que las recompensas y castigos estan fijadas en este entorno de la siguiente manera:__   \n", "__* Recibimos +20 puntos por un traslado exitoso.__  \n", "__* Perdemos 1 punto por cada intervalo de tiempo que tarda.__  \n", "__* Tambi\u00e9n hay una penalizaci\u00f3n de 10 puntos por acciones de recogida y dejada ilegales.__  \n", "__* Un movimiento que de lugar a un \"choque\" tiene la penalizaci\u00f3n de perder tiempo (el taxi no se desplaza pero se recibe la penalizaci\u00f3n de duraci\u00f3n)__"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Creando el entorno  ", "\n", "[al indice](#Contenidos)  ", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Tenemos 6 posibles acciones (sur, norte, este, oeste, recoger, dejar) y 500 posibles estados (que combinan la posici\u00f3n del taxi, el punto de recogida, el de entrega, la situaci\u00f3n del pasajero) codificados del 0 al 499"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sin aprendizaje por refuerzo  ", "\n", "[al indice](#Contenidos)  ", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["En tiempo de ejecuci\u00f3n de c\u00f3digo no ha sido nada... Pero imagina por un momento que hubiera sido una prueba en un entorno real... Recuerda que esta es una de las razones por las que se usan entornos simulados para aprender. Aunque no siempre es posible o recomendable (los coches aut\u00f3nomos de verdad aprenden sobre el terreno)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualizacion  ", "\n", "[al indice](#Contenidos)  ", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para poder ver qu\u00e9 es lo que realmente est\u00e1 haciendo el \"smart\"cab, vamos a crearnos una funci\u00f3n que pinte cada frame, dejando un intervalo de tiempo entre frame y frame para crear el efecto de animaci\u00f3n."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# Importamos dos comandos necesarios para limpiar la pantalla y para generar el intervalo entre frames\n", "from IPython.display import clear_output \n", "from time import sleep\n", "\n", "def episode_animation(frames):\n", "    for i, frame in enumerate(frames): # Recorremos todo el conjunto de frames\n", "        clear_output(wait=True) # Limpiamos la \"pantalla\"\n", "        print(frame['frame']) # Visualizamos el \"pantallazo\" resultado de cada acci\u00f3n\n", "        print(f\"Timestep: {i + 1}\") # Aumentamos el contador de pasos/steps\n", "        # Imprimimos el resto de valores correspondientes a cada frame y que hemos guardado al realizar el \"aprendizaje\"\n", "        print(f\"State: {frame['state']}\") \n", "        print(f\"Action: {frame['action']}\")\n", "        print(f\"Reward: {frame['reward']}\")\n", "        print(f\"Elapsed time (sec.): {frame['elapsed']}\")\n", "        sleep(.1) # \"Dormimos\" el programa un tiempo para que nuestro ojo pueda ver la imagen antes de borrarla y mostrar la siguiente\n", "        \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["episode_animation(frames[max(0,len(frames)-500):]) # Lanzamos la animacion, pero asegur\u00e1ndonos de que s\u00f3lo mostramos como mucho 500 frames. Si quieres verla entera (para gustos los colores...), s\u00f3lo tienes que quitar indexado y volver a ejecutar."]}, {"cell_type": "markdown", "metadata": {}, "source": ["C\u00f3mo puedes comprobar este mecanimo, aunque cumple con el cometido, tiene severas limitaciones:\n", "- Los tiempos son inaceptables\n", "- No se guarda el \"aprendizaje\", pero aunque lo hici\u00e9ramos, s\u00f3lo valdr\u00eda para la situaci\u00f3n de partida (el taxi en la posici\u00f3n 3,1. Recoger en Y entregar en R)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Necesitamos un mecanismo de mejora de la estrategia que no s\u00f3lo reduzca los tiempos y los optimice al m\u00e1ximo, sino que adem\u00e1s sea flexible como para poder aplicarse en cualquier situaci\u00f3n. Ese es el objetivo de la siguiente sesi\u00f3n: Q-Learning."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ahora t\u00fa"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Aunque a continuaci\u00f3n tienes un ejercicio espec\u00edfico, \u00bfpor qu\u00e9 no inventas una pol\u00edtica m\u00e1s acertada para nuestro SmartCab? Por ejemplo puedes jugar con la variable info, ya que eso no es hacer trampa. Nuestro SmartCab tendr\u00eda su LIDAR y otros sensores para detectar paredes y cuando se acaba el terreno por ejemplo. Es decir viendo la action_mask podr\u00eda evitarse acciones \"in\u00fatiles\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "nbformat": 4, "nbformat_minor": 2, "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}}